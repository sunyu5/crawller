{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import schedule\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/sunyu/Desktop/crawller/BITNEW/unibit_scraper/History_Data\")\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "https://query1.finance.yahoo.com/v7/finance/download/BTC-USD?period1=1553572800&period2=1553572800&interval=1d&events=history&crumb=O3403QhkvmT\n",
      "The data exists and can be scraped\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "def job():\n",
    "    test_url = \"https://finance.yahoo.com/quote/{ticker}/history?p={ticker}\"\n",
    "    crumb_exist = False\n",
    "    user_crumb = None\n",
    "    session = None\n",
    "    # contents = pd.read_csv(\"test.csv\", header=0)\n",
    "    contents = pd.read_csv(\"/Users/sunyu/Desktop/crawller/BITNEW/unibit_scraper/History_Data/crypto.csv\", header=0)\n",
    "    contents = pd.DataFrame(data = contents.ticker)\n",
    "    contents['downloaded'] = np.nan\n",
    "    contents = contents[0:1]\n",
    "    today = str(datetime.now().date())\n",
    "    tomorrow = str(datetime.now().date() + dt.timedelta(days=1))\n",
    "    yesterday = str(datetime.now().date() - dt.timedelta(days=1))\n",
    "    # mysql_url ='http://35.222.70.*/api/company/add/stockprice'\n",
    "    #mysql_url ='http://35.222.70.*/api/stock/crypto'\n",
    "    #try:\n",
    "        #while not crumb_exist:\n",
    "            #session = requests.Session()\n",
    "            #user_crumb = util.get_crumb(test_url, session)\n",
    "            #test_data = util.scrape_crypto(session, 'BTC-USD', '2001-01-02', '2018-08-28', user_crumb)\n",
    "            #if test_data is not None:\n",
    "                   # crumb_exist = True\n",
    "    #except Exception as e:\n",
    "        #print(str(e))\n",
    "\n",
    "    for index, row in contents.iterrows():\n",
    "        try:\n",
    "            session = requests.Session()\n",
    "            a = requests.adapters.HTTPAdapter(pool_connections =100,pool_maxsize =100,max_retries =3,pool_block= True)# limit size\n",
    "            b = requests.adapters.HTTPAdapter(pool_connections =100,pool_maxsize =100,max_retries =3,pool_block= True)\n",
    "            session.mount('http://', b)\n",
    "            session.mount('https://', a)\n",
    "            test_url = test_url.format(ticker = row[0])\n",
    "            user_crumb = util.get_crumb(test_url, session)\n",
    "        \n",
    "            if np.isnan(row[1]):\n",
    "                print(\"---------------------------\")\n",
    "                ticker_history_data = util.scrape_crypto(session, row[0], '2001-01-01', yesterday, user_crumb)\n",
    "                if ticker_history_data is None:\n",
    "                    print(\"The data does not exist and can not be scraped\")\n",
    "                    contents.loc[index, 'downloaded'] = 0\n",
    "                else:\n",
    "                    print(\"The data exists and can be scraped\")\n",
    "                    ticker_history_data = ticker_history_data.sort_index(ascending=False)\n",
    "                    for index_history, row_history in ticker_history_data.iterrows():\n",
    "                        #print(row_history[0])\n",
    "                        time_stamp = time.mktime(datetime.strptime(str(row_history[0]), \"%Y-%m-%d\").timetuple())\n",
    "                        new_cols = {\"crypto_name\": row[0], \"date\": row_history[0], \"open\": row_history[1],\n",
    "                                    \"high\": row_history[2], \"low\": row_history[3], \"close\": row_history[4],\n",
    "                                    \"adj_close\": row_history[5], \"volume\": row_history[6], \"timestamp\":int(time_stamp*1000)}\n",
    "                    \n",
    "                        util.insert_data_mysql(mysql_url, new_cols)\n",
    "                        #print(new_cols)\n",
    "            elif row[1] == 1:\n",
    "                print(\"The data was downloaded\")\n",
    "                ticker_history_data = util.scrape_crypto(session, row[0], today, tomorrow, user_crumb)\n",
    "                if ticker_history_data is None:\n",
    "                    print(\"The data of today does not exist\")\n",
    "                else:\n",
    "                    print(\"The data of today exists\")\n",
    "                    # new_cols = None\n",
    "                    for index_history, row_history in ticker_history_data.iterrows():\n",
    "                        time_stamp = time.mktime(datetime.strptime(str(row_history[0]), \"%Y-%m-%d\").timetuple())\n",
    "                        new_cols = {\"crypto_name\": row[0], \"date\": row_history[0], \"open\": row_history[1],\n",
    "                                    \"high\": row_history[2], \"low\": row_history[3], \"close\": row_history[4],\n",
    "                                    \"adj_close\": row_history[5], \"volume\": row_history[6],\"timestamp\":int(time_stamp*1000)}\n",
    "                        util.insert_data_mysql(mysql_url, new_cols)\n",
    "        except Exception as e:\n",
    "            print(\"exception is \",str(e))  \n",
    "    contents.to_csv(\"crypto.csv\", index=False, sep=',', encoding='utf-8')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #mysql_url ='http://35.222.70.*/api/stock/crypto'\n",
    "    # util.insert_data_mysql(mysql_url,{\"company_name\": \"AAPL\", \"date\": \"2019-2-19\", \"open\": 12.252, \"close\": 12.571, \"high\": 18.677,\"low\": 11.2345, \"adjClose\": 12.333, \"volume\": 123456})\n",
    "    job()\n",
    "    # schedule.every().day.at(\"24:00\").do(job)\n",
    "    # while True:\n",
    "    #     schedule.run_pending()\n",
    "    #     time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
